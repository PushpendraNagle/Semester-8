{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZyXCrFrmD5b",
        "outputId": "bd30e07a-e98d-44d7-b636-7548fd424df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ],
      "source": [
        "#Importing libraries\n",
        "import nltk, re, pprint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pprint, time\n",
        "import random\n",
        "import json\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "print (repr(string))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('penn-data.json', 'r') as infile:\n",
        "        json_data = json.load(infile)\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xji7VFYBoSlg",
        "outputId": "5338bd20-80c2-471f-f111-ca3ca24720fe"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(json_data[:5])\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52KmgSKuolvD",
        "outputId": "ddacf89b-1069-4544-e216-f536527f64cd"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Pierre Vinken, 61 years old, will join the board as a nonexecutive director Nov. 29.', ['NNP', 'NNP', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD']], ['Mr. Vinken is chairman of Elsevier N.V., the Dutch publishing group.', ['NNP', 'NNP', 'VBZ', 'NN', 'IN', 'NNP', 'NNP', 'DT', 'NNP', 'VBG', 'NN']], ['Rudolph Agnew, 55 years old and former chairman of Consolidated Gold Fields PLC, was named a nonexecutive director of this British industrial conglomerate.', ['NNP', 'NNP', 'CD', 'NNS', 'JJ', 'CC', 'JJ', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', 'VBD', 'VBN', 'DT', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'JJ', 'NN']], ['A form of asbestos once used to make Kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than 30 years ago, researchers reported.', ['DT', 'NN', 'IN', 'NN', 'RB', 'VBN', 'TO', 'VB', 'NNP', 'NN', 'NNS', 'VBZ', 'VBN', 'DT', 'JJ', 'NN', 'IN', 'NN', 'NNS', 'IN', 'DT', 'NN', 'IN', 'NNS', 'VBN', 'TO', 'PRP', 'RBR', 'IN', 'CD', 'NNS', 'IN', 'NNS', 'VBD']], ['The asbestos fiber, crocidolite, is unusually resilient once it enters the lungs, with even brief exposures to it causing symptoms that show up decades later, researchers said.', ['DT', 'NN', 'NN', 'NN', 'VBZ', 'RB', 'JJ', 'IN', 'PRP', 'VBZ', 'DT', 'NNS', 'IN', 'RB', 'JJ', 'NNS', 'TO', 'PRP', 'VBG', 'NNS', 'WDT', 'VBP', 'RP', 'NNS', 'JJ', 'NNS', 'VBD']]]\n",
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tags = set()\n",
        "tag_set = {'JJ', 'NNP', 'CD', 'JJS', 'FW', 'MD', 'VBP', 'NNPS', 'VBZ', 'WDT', 'PRP$', 'VBG', 'NNS', 'VBN', 'SYM', 'RB', 'POS', 'RBS', 'WP$', 'UH', 'PDT', 'IN', 'TO', 'WP', 'EX', 'VBD', 'JJR', 'RBR', 'VB', 'CC', 'PRP', 'LS', 'NN', 'DT', 'WRB', 'RP'}\n",
        "print(len(tag_set))\n",
        "print(sorted(tag_set))\n",
        "for i in range(len(json_data)):\n",
        "  for j in range(len(json_data[i][1])):\n",
        "    unique_tags.add(json_data[i][1][j])\n",
        "print(len(unique_tags))\n",
        "for _ in unique_tags:\n",
        "  print(_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx60I3yLZ3FN",
        "outputId": "14792a33-e02c-4af2-aec8-d28f80aadffb"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n",
            "['CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n",
            "41\n",
            "DT\n",
            ",\n",
            "JJ\n",
            "FW\n",
            "RBR\n",
            "RP\n",
            "PRP$\n",
            "VB\n",
            ":\n",
            "WP$\n",
            "LS\n",
            "#\n",
            "CC\n",
            "PRP\n",
            "VBN\n",
            "TO\n",
            "CD\n",
            "WP\n",
            "-RRB-\n",
            "WRB\n",
            "IN\n",
            "NN\n",
            "UH\n",
            "SYM\n",
            "MD\n",
            "-LRB-\n",
            "NNPS\n",
            "RBS\n",
            "NNP\n",
            "RB\n",
            "VBG\n",
            "JJR\n",
            "VBD\n",
            "PDT\n",
            "''\n",
            "VBZ\n",
            "WDT\n",
            "EX\n",
            "JJS\n",
            "VBP\n",
            "NNS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, test_set = train_test_split(json_data,test_size=0.2, random_state=777)\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1kjlk0FoxOf",
        "outputId": "3b58f978-cb5c-490b-b018-a597490c30c8"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXC993tXo2sn",
        "outputId": "05b2b7b0-df03-48da-ef74-e1e2a961c645"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1R9L8h1o-Gb",
        "outputId": "604fe2e3-c1c8-4ff7-bacc-b2e8f6e2be98"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2we4ABsTpPeo",
        "outputId": "9224961f-eb82-467b-b242-049a319e68fd"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[\"The group says standardized achievement test scores are greatly inflated because teachers often ``teach the test'' as Mrs. Yeargin did, although most are never caught.\", ['DT', 'NN', 'VBZ', 'JJ', 'NN', 'NN', 'NNS', 'VBP', 'RB', 'VBN', 'IN', 'NNS', 'RB', 'VBP', 'DT', 'NN', 'IN', 'NNP', 'NNP', 'VBD', 'IN', 'JJS', 'VBP', 'RB', 'VBN']], [\"Also, Mr. Canepa received a two-week suspension ``in a principal capacity.''\", ['RB', 'NNP', 'NNP', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN']], [\"That represents a very thin ``excess'' return, certainly far less than what most fundamental stock pickers claim to seek as their performance objective.\", ['DT', 'VBZ', 'DT', 'RB', 'JJ', 'JJ', 'NN', 'RB', 'RB', 'JJR', 'IN', 'WP', 'RBS', 'JJ', 'NN', 'NNS', 'VBP', 'TO', 'VB', 'IN', 'PRP$', 'NN', 'NN']], ['Last year, the average broker earned $71,309, 24% lower than in 1987.', ['JJ', 'NN', 'DT', 'JJ', 'NN', 'VBD', 'CD', 'CD', 'JJR', 'IN', 'IN', 'CD']], ['Columbia stock recently hit 4 1/8, after reaching 11 3/4 earlier this year on rumors that Mr. Spiegel would take the thrift private.', ['NNP', 'NN', 'RB', 'VBD', 'CD', 'CD', 'IN', 'VBG', 'CD', 'CD', 'RBR', 'DT', 'NN', 'IN', 'NNS', 'IN', 'NNP', 'NNP', 'MD', 'VB', 'DT', 'NN', 'JJ']]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def diff(list1, list2):\n",
        "    list2 = set(list2)\n",
        "    return [item for item in list1 if item not in list2]\n",
        "print (repr(string))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuBl1QEJpS9a",
        "outputId": "a0957c2e-c9eb-425b-fe93-7b24212a6023"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set[1][0])\n",
        "x = train_set[1][0]\n",
        "x = x.translate(str.maketrans('', '', string.punctuation))\n",
        "print(x)\n",
        "print(len(x.split(\" \")))\n",
        "print(train_set[1][1])\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JLNFY-nMHZi",
        "outputId": "327080a3-176c-40d5-c33f-648c653cb180"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Also, Mr. Canepa received a two-week suspension ``in a principal capacity.''\n",
            "Also Mr Canepa received a twoweek suspension in a principal capacity\n",
            "11\n",
            "['RB', 'NNP', 'NNP', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN']\n",
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_frequency(tag_dict):\n",
        "    result = 0\n",
        "\n",
        "    for tag, frequency in tag_dict.items():\n",
        "      #print(tag)\n",
        "      result += frequency\n",
        "\n",
        "    return result\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH6UA2NbUbBc",
        "outputId": "3e3c8563-f22b-43fa-c10a-cf5fd8ef253c"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_frequency = {}\n",
        "initial_probability = {}\n",
        "transition_frequency = {}\n",
        "transition_probability = {}\n",
        "emission_frequency = {}\n",
        "emission_probability = {}\n",
        "\n",
        "tags_dict = {}\n",
        "\n",
        "all_tags = []\n",
        "all_words = []\n",
        "\n",
        "for i in range(len(train_set)):\n",
        "  tags = []\n",
        "  words = []\n",
        "  sentence = train_set[i][0]\n",
        "  sentence_tags = train_set[i][1]\n",
        "  sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "  sentence = sentence.split(\" \")\n",
        "  initial_frequency[sentence_tags[0]] = initial_frequency.get(sentence_tags[0], 0) + 1\n",
        "  for _ in sentence:\n",
        "    words.append(_.lower())\n",
        "  for _ in sentence_tags:\n",
        "    tags.append(_)\n",
        "    tags_dict[_] = tags_dict.get(_, 0) + 1\n",
        "\n",
        "  for _ in words:\n",
        "    all_words.append(_)\n",
        "  for _ in tags:\n",
        "    all_tags.append(_)\n",
        "\n",
        "start_size = get_frequency(initial_frequency)\n",
        "print (repr(string))\n",
        "# for _ in all_tags:\n",
        "#   print(_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZnkHwxiM9jd",
        "outputId": "71131da9-80b7-4a3d-beaf-40ef40d49515"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tag, freq in tags_dict.items():\n",
        "    if tag in initial_frequency.keys():\n",
        "        initial_probability[tag] = initial_frequency[tag] / start_size\n",
        "    else:\n",
        "        initial_probability[tag] = 0.0 / start_size\n",
        "\n",
        "for i in range(len(all_tags)):\n",
        "    transition_frequency[all_tags[i]] = {}\n",
        "    transition_probability[all_tags[i]] = {}\n",
        "    emission_frequency[all_tags[i]] = {}\n",
        "    emission_probability[all_tags[i]] = {}\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQPW1GEsUkpV",
        "outputId": "5d2b3b47-dc05-4f7d-9c24-98c0f04bf86d"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### TRANSITION FREQUENCY AND PROBABILITY #####\n",
        "for i in range(len(train_set)):\n",
        "    sentence = train_set[i][0]\n",
        "    sentence_tags = train_set[i][1]\n",
        "\n",
        "    for j in range(len(sentence_tags)-1):\n",
        "        word_tag = sentence_tags[j]\n",
        "\n",
        "        for k, v in transition_frequency.items():\n",
        "            if k == word_tag:\n",
        "                transition_frequency[k].update({sentence_tags[j+1]: transition_frequency[k].get(\n",
        "                    sentence_tags[j+1], 0) + 1})\n",
        "\n",
        "for k, v in transition_frequency.items():\n",
        "    sum = get_frequency(v)\n",
        "    for k2, v2 in v.items():\n",
        "        transition_probability[k][k2] = v2 / sum\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaC_-OK5Up_8",
        "outputId": "bc074ed2-5cc2-4dd1-da9d-1971605b49ce"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### EMISSION FREQUENCY AND PROBABILITY #####\n",
        "for i in range(len(all_words)):\n",
        "    for k, v in emission_frequency.items():\n",
        "        if k == all_tags[i]:\n",
        "            emission_frequency[k].update({all_words[i]: emission_frequency[k].get(all_words[i], 0) + 1})\n",
        "\n",
        "for k, v in emission_frequency.items():\n",
        "    sum = get_frequency(v)\n",
        "    for k2, v2 in v.items():\n",
        "        emission_probability[k][k2] = v2 / sum\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC0sWOB3WtrK",
        "outputId": "5dadc197-2866-4f2c-ca32-1b4b9f9bc911"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_once_word(word_dict):\n",
        "    count = 0\n",
        "    for k, v in word_dict.items():\n",
        "        if v == 1:\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "\n",
        "all_test_words = []\n",
        "\n",
        "once_word_of_tags = {}\n",
        "\n",
        "# #### READ TEST DATA #####\n",
        "for i in range(len(test_set)):\n",
        "    sentence = test_set[i][0]\n",
        "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "    sentence = sentence.split(\" \")\n",
        "    sentence_tags = test_set[i][1]\n",
        "    tags = []\n",
        "    words = []\n",
        "\n",
        "    for j in range(len(sentence_tags)):\n",
        "        tags.append(sentence_tags[j])\n",
        "        words.append(sentence[j].lower())\n",
        "\n",
        "    for word in words:\n",
        "        all_test_words.append(word)\n",
        "\n",
        "for tag in emission_frequency.keys():\n",
        "    once_word_of_tags[tag] = get_once_word(emission_frequency[tag])\n",
        "\n",
        "# #### NUMBER OF UNKNOWN WORDS WHICH APPEARED IN TEST DATA #####\n",
        "unk_words = len(diff(all_test_words, all_words))\n",
        "print(unk_words)\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PmaBZJVW0FM",
        "outputId": "95cf4c0a-64e1-4518-9b76-fb69d01e24ce"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1247\n",
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### VITERBI ALGORITHM #####\n",
        "def viterbi(observation, states, one_freq_words, start_prob, transition_prob, emission_prob):\n",
        "    viterbi_matrix = {}\n",
        "    backpointer = {}\n",
        "    observation_length = len(observation)\n",
        "\n",
        "    # Initial word given\n",
        "    for tag in states:\n",
        "        first_word = observation[0]\n",
        "        if first_word in emission_prob[tag].keys():\n",
        "            viterbi_matrix[0, tag] = start_prob[tag] * emission_prob[tag].get(first_word, 0)\n",
        "            backpointer[0, tag] = None\n",
        "        else:\n",
        "            viterbi_matrix[0, tag] = start_prob[tag] * (one_freq_words[tag] / (unk_words * get_frequency(emission_frequency[tag])))\n",
        "            backpointer[0, tag] = None\n",
        "\n",
        "    # Examine the second word now, we already examined first word\n",
        "    for time_step, word in enumerate(observation[1:], start=1):\n",
        "        for tag in states:\n",
        "            if word in emission_prob[tag].keys():\n",
        "                p_emission = emission_prob[tag].get(word, 0)\n",
        "            else:\n",
        "                p_emission = one_freq_words[tag] / (unk_words * get_frequency(emission_frequency[tag]))\n",
        "\n",
        "            # argmax for the viterbi and backpointer\n",
        "            probability, state = max((viterbi_matrix[time_step - 1, prev_tag] * transition_prob[prev_tag].get(tag, 0),\n",
        "                                          prev_tag) for prev_tag in tags)\n",
        "\n",
        "            # max probability for the viterbi matrix\n",
        "            viterbi_matrix[time_step, tag] = probability * p_emission\n",
        "\n",
        "            # state of the max probability for the backpointer\n",
        "            backpointer[time_step, tag] = state\n",
        "\n",
        "    # Termination steps\n",
        "    probability, state = max((viterbi_matrix[observation_length - 1, tag] * transition_prob[tag].get('Punc', 0), tag)\n",
        "                             for tag in tags)\n",
        "    viterbi_matrix[observation_length, 'Punc'] = probability\n",
        "    backpointer[observation_length, 'Punc'] = state\n",
        "\n",
        "    # Return backtrace path...\n",
        "    backtrace_path = []\n",
        "    previous_state = 'Punc'\n",
        "    for index in range(observation_length, 0, -1):\n",
        "        state = backpointer[index, previous_state]\n",
        "        backtrace_path.append(state)\n",
        "        previous_state = state\n",
        "\n",
        "    # We are tracing back through the pointers, so the path is in reverse\n",
        "    backtrace_path = list(reversed(backtrace_path))\n",
        "    return backtrace_path\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWQqqytlFLuZ",
        "outputId": "838b9b05-a614-4b2d-db00-01ee6f401179"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_accuracy = {}\n",
        "tag_total = {}\n",
        "def calculate_accuracy(real_tags, test_tags):\n",
        "    total_tags = 0\n",
        "    true = 0\n",
        "    for i in range(len(test_tags)):\n",
        "        if test_tags[i] == real_tags[i]:\n",
        "            true += 1\n",
        "            tag_accuracy[real_tags[i]] = tag_accuracy.get(real_tags[i],0) + 1\n",
        "        total_tags += 1\n",
        "        tag_total[real_tags[i]] = tag_total.get(real_tags[i],0) + 1\n",
        "    return true, total_tags\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIpreRhSFQp-",
        "outputId": "e2352f80-ee82-42fa-a027-4391480a7d4a"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set[0][0])\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PdbNhquI5Mx",
        "outputId": "a3b622b7-62cf-4b83-ac3b-ea3af50aee9a"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None of the securities will be eligible for when-issued trading until Congress approves an increase in the debt ceiling, clearing the way for a formal offering, Mr. Basham said.\n",
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### CHECK THE TAGS IN TEST SENTENCES #####\n",
        "f = open(\"output.txt\", \"w\", encoding='utf-8')\n",
        "\n",
        "acc_total = 0\n",
        "acc_correct = 0\n",
        "print (repr(string))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdxwiYIdFcTp",
        "outputId": "32bf2602-6367-4707-9659-5a29b1227138"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_set)):\n",
        "    tags = []\n",
        "    words = []\n",
        "    #sentence_temp = test_set[i][0]\n",
        "    #print (repr(string))\n",
        "    sentence = test_set[i][0].translate(str.maketrans('', '', string.punctuation))\n",
        "    actual_words = sentence.split(\" \")\n",
        "    sentence_tags = test_set[i][1]\n",
        "\n",
        "    for j in range(len(sentence_tags)):\n",
        "        tags.append(sentence_tags[j])\n",
        "        words.append(actual_words[j].lower())\n",
        "\n",
        "    viterbi_result = viterbi(words, tags_dict.keys(), once_word_of_tags, initial_probability, transition_probability,\n",
        "                             emission_probability)\n",
        "\n",
        "    temp = \"\"\n",
        "    for j in range(len(actual_words)):\n",
        "        temp += actual_words[j] + \"/\" + viterbi_result[j] + \" \"\n",
        "\n",
        "    temp += \"\\n\"\n",
        "\n",
        "    f.write(temp)\n",
        "\n",
        "    true, total = calculate_accuracy(tags, viterbi_result)\n",
        "\n",
        "    acc_total += total\n",
        "    acc_correct += true\n",
        "\n",
        "temp = \"Accuracy: \" + str((acc_correct / acc_total) * 100)\n",
        "print(\"Correct found tags:\", acc_correct)\n",
        "print(len(tag_accuracy))\n",
        "for tag in tag_accuracy:\n",
        "  #print(tag)\n",
        "  print(\"Accuracy of \" + str(tag) + \" :\" + str((tag_accuracy[tag]/tag_total[tag])*100))\n",
        "print(\"Total words:\", acc_total)\n",
        "print(temp)\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KK7Hbj0L9MI",
        "outputId": "f11fe67b-022d-4055-c3d4-4cb53b31f367"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct found tags: 13518\n",
            "36\n",
            "Accuracy of NN :75.10899722552516\n",
            "Accuracy of IN :97.55970924195223\n",
            "Accuracy of DT :98.73976055450535\n",
            "Accuracy of NNS :70.5685618729097\n",
            "Accuracy of MD :95.76719576719577\n",
            "Accuracy of VB :91.4\n",
            "Accuracy of JJ :74.11255411255411\n",
            "Accuracy of NNP :79.83706720977597\n",
            "Accuracy of CC :97.49430523917995\n",
            "Accuracy of VBD :88.09523809523809\n",
            "Accuracy of PRP :94.05099150141642\n",
            "Accuracy of TO :96.60633484162896\n",
            "Accuracy of CD :75.56497175141243\n",
            "Accuracy of VBG :61.03448275862069\n",
            "Accuracy of RB :75.29411764705883\n",
            "Accuracy of JJR :78.37837837837837\n",
            "Accuracy of VBP :79.6875\n",
            "Accuracy of WDT :88.88888888888889\n",
            "Accuracy of VBZ :88.19277108433735\n",
            "Accuracy of EX :93.75\n",
            "Accuracy of JJS :79.3103448275862\n",
            "Accuracy of -RRB- :86.95652173913044\n",
            "Accuracy of VBN :76.06635071090048\n",
            "Accuracy of PRP$ :92.64705882352942\n",
            "Accuracy of WP :96.07843137254902\n",
            "Accuracy of NNPS :51.28205128205128\n",
            "Accuracy of RBR :75.0\n",
            "Accuracy of : :86.66666666666667\n",
            "Accuracy of WRB :94.5945945945946\n",
            "Accuracy of RP :66.66666666666666\n",
            "Accuracy of -LRB- :95.0\n",
            "Accuracy of # :100.0\n",
            "Accuracy of PDT :60.0\n",
            "Accuracy of RBS :50.0\n",
            "Accuracy of LS :25.0\n",
            "Accuracy of WP$ :100.0\n",
            "Total words: 16154\n",
            "Accuracy: 83.68206017085552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('penn-data.json', 'r') as infile:\n",
        "        json_data1 = json.load(infile)\n",
        "print (repr(string))"
      ],
      "metadata": {
        "id": "5ygz_D78MyIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "361d94bf-8fc6-4189-e580-577e4d3dff05"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_set = {'NN', 'NNS', 'NNP', 'NNPS'}\n",
        "V_set = {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}\n",
        "A_set = {'JJ', 'JJR', 'JJS', 'RB', 'RB', 'RBR', 'RBS', 'WRB'}\n",
        "for i in range(len(json_data1)):\n",
        "  for j in range(len(json_data1[i][1])):\n",
        "    if json_data1[i][1][j] in N_set:\n",
        "      json_data1[i][1][j] = 'N'\n",
        "    elif json_data1[i][1][j] in V_set:\n",
        "      json_data1[i][1][j] = 'V'\n",
        "    elif json_data1[i][1][j] in A_set:\n",
        "      json_data1[i][1][j] = 'A'\n",
        "    else:\n",
        "      json_data1[i][1][j] = 'O'"
      ],
      "metadata": {
        "id": "67cgNVJ0P_fJ"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json_data1[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B65dWNF4SRsr",
        "outputId": "2f78f37d-0d85-4915-e64b-49b8069929bd"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['N', 'N', 'O', 'N', 'A', 'O', 'V', 'O', 'N', 'O', 'O', 'A', 'N', 'N', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, test_set = train_test_split(json_data1,test_size=0.2, random_state=777)"
      ],
      "metadata": {
        "id": "6Nuq6brUSVdr"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_frequency = {}\n",
        "initial_probability = {}\n",
        "transition_frequency = {}\n",
        "transition_probability = {}\n",
        "emission_frequency = {}\n",
        "emission_probability = {}\n",
        "\n",
        "tags_dict = {}\n",
        "\n",
        "all_tags = []\n",
        "all_words = []\n",
        "\n",
        "for i in range(len(train_set)):\n",
        "  tags = []\n",
        "  words = []\n",
        "  sentence = train_set[i][0]\n",
        "  sentence_tags = train_set[i][1]\n",
        "  sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "  sentence = sentence.split(\" \")\n",
        "  initial_frequency[sentence_tags[0]] = initial_frequency.get(sentence_tags[0], 0) + 1\n",
        "  for _ in sentence:\n",
        "    words.append(_.lower())\n",
        "  for _ in sentence_tags:\n",
        "    tags.append(_)\n",
        "    tags_dict[_] = tags_dict.get(_, 0) + 1\n",
        "\n",
        "  for _ in words:\n",
        "    all_words.append(_)\n",
        "  for _ in tags:\n",
        "    all_tags.append(_)\n",
        "\n",
        "start_size = get_frequency(initial_frequency)\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9XYc8ocTAzt",
        "outputId": "5760ee3c-fd64-4d4a-b547-02d4ca3c5969"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tag, freq in tags_dict.items():\n",
        "    if tag in initial_frequency.keys():\n",
        "        initial_probability[tag] = initial_frequency[tag] / start_size\n",
        "    else:\n",
        "        initial_probability[tag] = 0.0 / start_size\n",
        "\n",
        "for i in range(len(all_tags)):\n",
        "    transition_frequency[all_tags[i]] = {}\n",
        "    transition_probability[all_tags[i]] = {}\n",
        "    emission_frequency[all_tags[i]] = {}\n",
        "    emission_probability[all_tags[i]] = {}\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBREw-ESTIpo",
        "outputId": "79002805-bae1-4bb5-a6d9-a03c9e05bef2"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### TRANSITION FREQUENCY AND PROBABILITY #####\n",
        "for i in range(len(train_set)):\n",
        "    sentence = train_set[i][0]\n",
        "    sentence_tags = train_set[i][1]\n",
        "\n",
        "    for j in range(len(sentence_tags)-1):\n",
        "        word_tag = sentence_tags[j]\n",
        "\n",
        "        for k, v in transition_frequency.items():\n",
        "            if k == word_tag:\n",
        "                transition_frequency[k].update({sentence_tags[j+1]: transition_frequency[k].get(\n",
        "                    sentence_tags[j+1], 0) + 1})\n",
        "\n",
        "for k, v in transition_frequency.items():\n",
        "    sum = get_frequency(v)\n",
        "    for k2, v2 in v.items():\n",
        "        transition_probability[k][k2] = v2 / sum\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2byafas1TM97",
        "outputId": "f88530df-b517-46f8-b070-0721aabd99ec"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### EMISSION FREQUENCY AND PROBABILITY #####\n",
        "for i in range(len(all_words)):\n",
        "    for k, v in emission_frequency.items():\n",
        "        if k == all_tags[i]:\n",
        "            emission_frequency[k].update({all_words[i]: emission_frequency[k].get(all_words[i], 0) + 1})\n",
        "\n",
        "for k, v in emission_frequency.items():\n",
        "    sum = get_frequency(v)\n",
        "    for k2, v2 in v.items():\n",
        "        emission_probability[k][k2] = v2 / sum\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UoHYPfJTP_i",
        "outputId": "40e0754e-9a90-4805-93cb-b840af6bc9a4"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### READ TEST DATA #####\n",
        "for i in range(len(test_set)):\n",
        "    sentence = test_set[i][0]\n",
        "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "    sentence = sentence.split(\" \")\n",
        "    sentence_tags = test_set[i][1]\n",
        "    tags = []\n",
        "    words = []\n",
        "\n",
        "    for j in range(len(sentence_tags)):\n",
        "        tags.append(sentence_tags[j])\n",
        "        words.append(sentence[j].lower())\n",
        "\n",
        "    for word in words:\n",
        "        all_test_words.append(word)\n",
        "\n",
        "for tag in emission_frequency.keys():\n",
        "    once_word_of_tags[tag] = get_once_word(emission_frequency[tag])\n",
        "\n",
        "# #### NUMBER OF UNKNOWN WORDS WHICH APPEARED IN TEST DATA #####\n",
        "unk_words = len(diff(all_test_words, all_words))\n",
        "print(unk_words)\n",
        "print (repr(string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4OOfWm6TUy2",
        "outputId": "bd7a9406-4de5-47e5-d411-448d603cc34a"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2494\n",
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_accuracy = {}\n",
        "tag_total = {}\n",
        "# #### CHECK THE TAGS IN TEST SENTENCES #####\n",
        "f = open(\"output.txt\", \"w\", encoding='utf-8')\n",
        "\n",
        "acc_total = 0\n",
        "acc_correct = 0\n",
        "print (repr(string))\n",
        "\n",
        "for i in range(len(test_set)):\n",
        "    tags = []\n",
        "    words = []\n",
        "    #sentence_temp = test_set[i][0]\n",
        "    #print (repr(string))\n",
        "    sentence = test_set[i][0].translate(str.maketrans('', '', string.punctuation))\n",
        "    actual_words = sentence.split(\" \")\n",
        "    sentence_tags = test_set[i][1]\n",
        "\n",
        "    for j in range(len(sentence_tags)):\n",
        "        tags.append(sentence_tags[j])\n",
        "        words.append(actual_words[j].lower())\n",
        "\n",
        "    viterbi_result = viterbi(words, tags_dict.keys(), once_word_of_tags, initial_probability, transition_probability,\n",
        "                             emission_probability)\n",
        "\n",
        "    temp = \"\"\n",
        "    for j in range(len(actual_words)):\n",
        "        temp += actual_words[j] + \"/\" + viterbi_result[j] + \" \"\n",
        "\n",
        "    temp += \"\\n\"\n",
        "\n",
        "    f.write(temp)\n",
        "\n",
        "    true, total = calculate_accuracy(tags, viterbi_result)\n",
        "\n",
        "    acc_total += total\n",
        "    acc_correct += true\n",
        "\n",
        "temp = \"Accuracy: \" + str((acc_correct / acc_total) * 100)\n",
        "print(\"Correct found tags:\", acc_correct)\n",
        "print(len(tag_accuracy))\n",
        "for tag in tag_accuracy:\n",
        "  #print(tag)\n",
        "  print(\"Accuracy of \" + str(tag) + \" :\" + str((tag_accuracy[tag]/tag_total[tag])*100))\n",
        "print(\"Total words:\", acc_total)\n",
        "print(temp)\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4iYjSa8TczZ",
        "outputId": "cac4dbb7-aa91-4f84-af43-72d6393e44a0"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'string' from '/usr/lib/python3.8/string.py'>\n",
            "Correct found tags: 14186\n",
            "4\n",
            "Accuracy of N :85.31981824536875\n",
            "Accuracy of O :95.72649572649573\n",
            "Accuracy of V :83.32670115399921\n",
            "Accuracy of A :75.53133514986376\n",
            "Total words: 16154\n",
            "Accuracy: 87.81725888324873\n"
          ]
        }
      ]
    }
  ]
}